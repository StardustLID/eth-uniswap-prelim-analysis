{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Token Volume Analysis\n",
    "In this section, we focus on the tokens' 24H volume trend. Both time and frequency domain techniques will be used. Hourly volume analysis may be added in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Library\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Third Party Library\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.pyplot import MaxNLocator\n",
    "\n",
    "# Local Folder Library\n",
    "from pyammanalysis.util import read_yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "config = read_yaml(\"../config.yaml\")\n",
    "SUBPLOTS_PER_ROW = config[\"SUBPLOTS_PER_ROW\"]\n",
    "\n",
    "# data folder paths\n",
    "DATA_PATH = \"data\"\n",
    "\n",
    "tokens_df = pd.read_csv(os.path.join(DATA_PATH, \"tokens_df.csv\"))\n",
    "token_names = tokens_df[\"symbol\"]\n",
    "\n",
    "token_day_df = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, \"token_day_df.csv\"), parse_dates=[\"date\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: cleanse the gaps and erroneous entries.\n",
    "# also, avoid the first few days of token launch\n",
    "\n",
    "# for now, do naive plots and correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Domain\n",
    "### Time Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_tokens = []\n",
    "\n",
    "plt.figure(figsize=(19, 9))\n",
    "for token_name in token_names:\n",
    "    try:\n",
    "        plt.plot(token_day_df[\"date\"], token_day_df[token_name + \"_volumeUSD\"])\n",
    "    except:\n",
    "        missing_tokens.append(token_name)\n",
    "plt.title(\"24H Volume over Time\")\n",
    "plt.xlabel(\"date\")\n",
    "plt.ylabel(\"24H Volume (in USD)\")\n",
    "plt.legend(token_names, loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(missing_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Histogram\n",
    "Observe the distribution of the prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 16))\n",
    "axes = fig.subplots(4, SUBPLOTS_PER_ROW)\n",
    "for i, token_name in enumerate(token_names):\n",
    "    volumeUSD_series = token_day_df[token_name + \"_volumeUSD\"]\n",
    "    ax = axes[math.floor(i / SUBPLOTS_PER_ROW), i % SUBPLOTS_PER_ROW]\n",
    "    ax.title.set_text(token_name)\n",
    "    ax.hist(volumeUSD_series, bins=100, range=(0, volumeUSD_series.quantile(0.99)))\n",
    "\n",
    "    # force y-axis ticks to use integers\n",
    "    ax.get_yaxis().set_major_locator(MaxNLocator(integer=True))\n",
    "\n",
    "    # highlight 25%-75% percentile\n",
    "    lq = volumeUSD_series.quantile(0.25)\n",
    "    uq = volumeUSD_series.quantile(0.75)\n",
    "    ax.axvspan(lq, uq, color=\"green\", alpha=0.25)\n",
    "\n",
    "fig.suptitle(\"24H Volume Distributions\")\n",
    "fig.supxlabel(\"24H Volume (in USD)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df = token_day_df.drop(columns=\"timestamp\")\n",
    "# note: df.std() is normalized by N-1\n",
    "token_metrics_df = pd.DataFrame(\n",
    "    data=[token_df.mean(), token_df.std()], index=[\"mean\", \"stdev\"]\n",
    ")\n",
    "token_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "### TVL Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_day_tvl_df = token_day_df.loc[\n",
    "    :, token_day_df.columns.str.endswith(\"totalValueLockedUSD\")\n",
    "].rename(lambda x: x.split(\"_\")[0], axis=\"columns\")\n",
    "corr_df = token_day_tvl_df.corr(method=\"pearson\").rename_axis(\"symbol\", axis=1)\n",
    "corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the bottom triangle since it repeats itself\n",
    "mask = np.zeros_like(corr_df)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# generate plot\n",
    "plt.figure(figsize=(18, 18))\n",
    "plt.title(\"Token TVL Pearson Correlation\")\n",
    "sns.heatmap(corr_df, cmap=\"RdYlGn\", vmax=1.0, vmin=-1.0, mask=mask, linewidths=2.5)\n",
    "plt.yticks(rotation=0)\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Domain\n",
    "### Fast Fourier Transform (FFT)\n",
    "FFT computes the frequency content of the prices as signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 16))\n",
    "axes = fig.subplots(4, SUBPLOTS_PER_ROW)\n",
    "for i, token_name in enumerate(token_names):\n",
    "    date_volume_df = token_day_df[[\"date\", token_name + \"_volumeUSD\"]].dropna()\n",
    "    volumeUSD_series = date_volume_df[token_name + \"_volumeUSD\"]\n",
    "\n",
    "    # reference for zero-mean signal:\n",
    "    # https://dsp.stackexchange.com/questions/46950/removing-mean-from-signal-massively-distorts-fft\n",
    "    # only keep those with freq STRICTLY > 0\n",
    "    f_max = math.ceil(date_volume_df.shape[0] / 2)\n",
    "    Y = abs(np.fft.fft(volumeUSD_series - volumeUSD_series.mean()))[1:f_max]\n",
    "    freq = np.fft.fftfreq(date_volume_df.shape[0], 1)[1:f_max]\n",
    "\n",
    "    ax = axes[math.floor(i / SUBPLOTS_PER_ROW), i % SUBPLOTS_PER_ROW]\n",
    "    ax.title.set_text(token_name)\n",
    "    ax.plot(freq, Y)\n",
    "\n",
    "fig.suptitle(\"24H Volume FFT\")\n",
    "fig.supxlabel(\"freq (in /day)\")\n",
    "fig.supylabel(\"24H Volume (in USD)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 16))\n",
    "axes = fig.subplots(4, SUBPLOTS_PER_ROW)\n",
    "for i, token_name in enumerate(token_names):\n",
    "    date_volume_df = token_day_df[[\"date\", token_name + \"_volumeUSD\"]].dropna()\n",
    "    volumeUSD_series = date_volume_df[token_name + \"_volumeUSD\"]\n",
    "\n",
    "    # reference for zero-mean signal:\n",
    "    # https://dsp.stackexchange.com/questions/46950/removing-mean-from-signal-massively-distorts-fft\n",
    "    # only keep those with freq STRICTLY > 0\n",
    "    f_max = math.ceil(date_volume_df.shape[0] / 2)\n",
    "    Y = abs(np.fft.fft(volumeUSD_series - volumeUSD_series.mean()))[1:f_max]\n",
    "    freq = np.fft.fftfreq(date_volume_df.shape[0], 1)[1:f_max]\n",
    "\n",
    "    # c.f. power spectral density in signal processing\n",
    "    spectrum = Y.real * Y.real + Y.imag * Y.imag\n",
    "\n",
    "    ax = axes[math.floor(i / SUBPLOTS_PER_ROW), i % SUBPLOTS_PER_ROW]\n",
    "    ax.title.set_text(token_name)\n",
    "    ax.set_xlim(left=freq[1], right=freq[-1])\n",
    "\n",
    "    # Note: this is possible because FFT must give positive values,\n",
    "    # so that their logarithms always exist.\n",
    "    # plot log10(spectrum) against frequency\n",
    "    ax.semilogy(freq, spectrum)\n",
    "\n",
    "fig.suptitle(\"Semilog Plot of 24H Volume FFT\")\n",
    "fig.supxlabel(\"freq (in /day)\")\n",
    "fig.supylabel(\"Magnitude\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('eth-uniswap-prelim-analysis-3WCyaTCY-py3.8')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c4b7809061330062f8c735d3b8d55bf6a8b663fb533c57ef3c9775113b0f4a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
